{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy import stats\n",
    "from sklearn.decomposition import PCA\n",
    "from IPython.core.debugger import set_trace\n",
    "import pickle\n",
    "import os\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to estimate cost for each lambda, by voxel:\n",
    "from __future__ import division                                              \n",
    "\n",
    "from numpy.linalg import inv, svd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import Ridge, RidgeCV\n",
    "import time \n",
    "from scipy.stats import zscore\n",
    "\n",
    "\n",
    "def corr(X,Y):\n",
    "    return np.mean(zscore(X)*zscore(Y),0)\n",
    "\n",
    "def R2(Pred,Real):\n",
    "    SSres = np.mean((Real-Pred)**2,0)\n",
    "    SStot = np.var(Real,0)\n",
    "    return np.nan_to_num(1-SSres/SStot)\n",
    "\n",
    "def R2r(Pred,Real):\n",
    "    R2rs = R2(Pred,Real)\n",
    "    ind_neg = R2rs<0\n",
    "    R2rs = np.abs(R2rs)\n",
    "    R2rs = np.sqrt(R2rs)\n",
    "    R2rs[ind_neg] *= - 1\n",
    "    return R2rs\n",
    "\n",
    "def ridge(X,Y,lmbda):\n",
    "    return np.dot(inv(X.T.dot(X)+lmbda*np.eye(X.shape[1])),X.T.dot(Y))\n",
    "\n",
    "def ridge_by_lambda(X, Y, Xval, Yval, lambdas=np.array([0.1,1,10,100,1000])):\n",
    "    error = np.zeros((lambdas.shape[0],Y.shape[1]))\n",
    "    for idx,lmbda in enumerate(lambdas):\n",
    "        weights = ridge(X,Y,lmbda)\n",
    "        error[idx] = 1 - R2(np.dot(Xval,weights),Yval)\n",
    "    return error\n",
    "\n",
    "def ridge_sk(X,Y,lmbda):\n",
    "    rd = Ridge(alpha = lmbda)\n",
    "    rd.fit(X,Y)\n",
    "    return rd.coef_.T\n",
    "\n",
    "def ridgeCV_sk(X,Y,lmbdas):\n",
    "    rd = RidgeCV(alphas = lmbdas,solver = 'svd')\n",
    "    rd.fit(X,Y)\n",
    "    return rd.coef_.T\n",
    "\n",
    "def ridge_by_lambda_sk(X, Y, Xval, Yval, lambdas=np.array([0.1,1,10,100,1000])):\n",
    "    error = np.zeros((lambdas.shape[0],Y.shape[1]))\n",
    "    for idx,lmbda in enumerate(lambdas):\n",
    "        weights = ridge_sk(X,Y,lmbda)\n",
    "        error[idx] = 1 -  R2(np.dot(Xval,weights),Yval)\n",
    "    return error\n",
    "\n",
    "def ridge_svd(X,Y,lmbda):\n",
    "    U, s, Vt = svd(X, full_matrices=False)\n",
    "    d = s / (s** 2 + lmbda)\n",
    "    return np.dot(Vt,np.diag(d).dot(U.T.dot(Y)))\n",
    "\n",
    "def ridge_by_lambda_svd(X, Y, Xval, Yval, lambdas=np.array([0.1,1,10,100,1000])):\n",
    "    error = np.zeros((lambdas.shape[0],Y.shape[1]))\n",
    "    U, s, Vt = svd(X, full_matrices=False)\n",
    "    for idx,lmbda in enumerate(lambdas):\n",
    "        d = s / (s** 2 + lmbda)\n",
    "        weights = np.dot(Vt,np.diag(d).dot(U.T.dot(Y)))\n",
    "        error[idx] = 1 - R2(np.dot(Xval,weights),Yval)\n",
    "    return error\n",
    "\n",
    "\n",
    "def kernel_ridge(X,Y,lmbda):\n",
    "    return np.dot(X.T.dot(inv(X.dot(X.T)+lmbda*np.eye(X.shape[0]))),Y)\n",
    "\n",
    "def kernel_ridge_by_lambda(X, Y, Xval, Yval, lambdas=np.array([0.1,1,10,100,1000])):\n",
    "    error = np.zeros((lambdas.shape[0],Y.shape[1]))\n",
    "    for idx,lmbda in enumerate(lambdas):\n",
    "        weights = kernel_ridge(X,Y,lmbda)\n",
    "        error[idx] = 1 - R2(np.dot(Xval,weights),Yval)\n",
    "    return error\n",
    "\n",
    "\n",
    "def kernel_ridge_svd(X,Y,lmbda):\n",
    "    U, s, Vt = svd(X.T, full_matrices=False)\n",
    "    d = s / (s** 2 + lmbda)\n",
    "    return np.dot(np.dot(U,np.diag(d).dot(Vt)),Y)\n",
    "\n",
    "def kernel_ridge_by_lambda_svd(X, Y, Xval, Yval, lambdas=np.array([0.1,1,10,100,1000])):\n",
    "    error = np.zeros((lambdas.shape[0],Y.shape[1]))\n",
    "    U, s, Vt = svd(X.T, full_matrices=False)\n",
    "    for idx,lmbda in enumerate(lambdas):\n",
    "        d = s / (s** 2 + lmbda)\n",
    "        weights = np.dot(np.dot(U,np.diag(d).dot(Vt)),Y)\n",
    "        error[idx] = 1 - R2(np.dot(Xval,weights),Yval)\n",
    "    return error\n",
    "\n",
    "\n",
    "def cross_val_ridge(train_features,train_data, n_splits = 10, \n",
    "                    lambdas = np.array([10**i for i in range(-6,10)]),\n",
    "                    method = 'plain',\n",
    "                    do_plot = False):\n",
    "    \n",
    "    ridge_1 = dict(plain = ridge_by_lambda,\n",
    "                   svd = ridge_by_lambda_svd,\n",
    "                   kernel_ridge = kernel_ridge_by_lambda,\n",
    "                   kernel_ridge_svd = kernel_ridge_by_lambda_svd,\n",
    "                   ridge_sk = ridge_by_lambda_sk)[method]\n",
    "    ridge_2 = dict(plain = ridge,\n",
    "                   svd = ridge_svd,\n",
    "                   kernel_ridge = kernel_ridge,\n",
    "                   kernel_ridge_svd = kernel_ridge_svd,\n",
    "                   ridge_sk = ridge_sk)[method]\n",
    "    \n",
    "    n_voxels = train_data.shape[1]\n",
    "    nL = lambdas.shape[0]\n",
    "    r_cv = np.zeros((nL, train_data.shape[1]))\n",
    "\n",
    "    kf = KFold(n_splits=n_splits)\n",
    "    start_t = time.time()\n",
    "    for icv, (trn, val) in enumerate(kf.split(train_data)):\n",
    "#         print('ntrain = {}'.format(train_features[trn].shape[0]))\n",
    "        cost = ridge_1(train_features[trn],train_data[trn],\n",
    "                               train_features[val],train_data[val], \n",
    "                               lambdas=lambdas)\n",
    "        if do_plot:\n",
    "            import matplotlib.pyplot as plt\n",
    "            plt.figure()\n",
    "            plt.imshow(cost,aspect = 'auto')\n",
    "        r_cv += cost\n",
    "#         if icv%3 ==0:\n",
    "#             print(icv)\n",
    "#         print('average iteration length {}'.format((time.time()-start_t)/(icv+1)))\n",
    "    if do_plot:\n",
    "        plt.figure()\n",
    "        plt.imshow(r_cv,aspect='auto',cmap = 'RdBu_r');\n",
    "\n",
    "    argmin_lambda = np.argmin(r_cv,axis = 0)\n",
    "    weights = np.zeros((train_features.shape[1],train_data.shape[1]))\n",
    "    for idx_lambda in range(lambdas.shape[0]): # this is much faster than iterating over voxels!\n",
    "        idx_vox = argmin_lambda == idx_lambda\n",
    "        weights[:,idx_vox] = ridge_2(train_features, train_data[:,idx_vox],lambdas[idx_lambda])\n",
    "    if do_plot:\n",
    "        plt.figure()\n",
    "        plt.imshow(weights,aspect='auto',cmap = 'RdBu_r',vmin = -0.5,vmax = 0.5);\n",
    "\n",
    "    return weights, np.array([lambdas[i] for i in argmin_lambda])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def GCV_ridge(train_features,train_data,lambdas = np.array([10**i for i in range(-6,10)])):\n",
    "    \n",
    "    n_lambdas = lambdas.shape[0]\n",
    "    n_voxels = train_data.shape[1]\n",
    "    n_time = train_data.shape[0]\n",
    "    n_p = train_features.shape[1]\n",
    "\n",
    "    CVerr = np.zeros((n_lambdas, n_voxels))\n",
    "\n",
    "    # % If we do an eigendecomp first we can quickly compute the inverse for many different values\n",
    "    # % of lambda. SVD uses X = UDV' form.\n",
    "    # % First compute K0 = (X'X + lambda*I) where lambda = 0.\n",
    "    #K0 = np.dot(train_features,train_features.T)\n",
    "    print('Running svd',)\n",
    "    start_time = time.time()\n",
    "    [U,D,Vt] = svd(train_features,full_matrices=False)\n",
    "    V = Vt.T\n",
    "    print(U.shape,D.shape,Vt.shape)\n",
    "    print('svd time: {}'.format(time.time() - start_time))\n",
    "\n",
    "    for i,regularizationParam in enumerate(lambdas):\n",
    "        regularizationParam = lambdas[i]\n",
    "        print('CVLoop: Testing regularization param: {}'.format(regularizationParam))\n",
    "\n",
    "        #Now we can obtain Kinv for any lambda doing Kinv = V * (D + lambda*I)^-1 U'\n",
    "        dlambda = D**2 + np.eye(n_p)*regularizationParam\n",
    "        dlambdaInv = np.diag(D / np.diag(dlambda))\n",
    "        KlambdaInv = V.dot(dlambdaInv).dot(U.T)\n",
    "        \n",
    "        # Compute S matrix of Hastie Trick  H = X(XT X + lambdaI)-1XT\n",
    "        S = np.dot(U, np.diag(D * np.diag(dlambdaInv))).dot(U.T)\n",
    "        denum = 1-np.trace(S)/n_time\n",
    "        \n",
    "        # Solve for weight matrix so we can compute residual\n",
    "        weightMatrix = KlambdaInv.dot(train_data);\n",
    "\n",
    "\n",
    "#         Snorm = np.tile(1 - np.diag(S) , (n_voxels, 1)).T\n",
    "        YdiffMat = (train_data - (train_features.dot(weightMatrix)));\n",
    "        YdiffMat = YdiffMat / denum;\n",
    "        CVerr[i,:] = (1/n_time)*np.sum(YdiffMat * YdiffMat,0);\n",
    "\n",
    "\n",
    "    # try using min of avg err\n",
    "    minerrIndex = np.argmin(CVerr,axis = 0);\n",
    "    r=np.zeros((n_voxels));\n",
    "\n",
    "    for nPar,regularizationParam in enumerate(lambdas):\n",
    "        ind = np.where(minerrIndex==nPar)[0];\n",
    "        if len(ind)>0:\n",
    "            r[ind] = regularizationParam;\n",
    "            print('{}% of outputs with regularization param: {}'.format(int(len(ind)/n_voxels*100),\n",
    "                                                                        regularizationParam))\n",
    "            # got good param, now obtain weights\n",
    "            dlambda = D**2 + np.eye(n_p)*regularizationParam\n",
    "            dlambdaInv = np.diag(D / np.diag(dlambda))\n",
    "            KlambdaInv = V.dot(dlambdaInv).dot(U.T)\n",
    "\n",
    "            weightMatrix[:,ind] = KlambdaInv.dot(train_data[:,ind]);\n",
    "\n",
    "\n",
    "    return weightMatrix, r\n",
    "\n",
    "def sub_to_subjectnum(sub):\n",
    "    for i in range(len(all_subjects)):\n",
    "        if all_subjects[i] == sub:\n",
    "            return i+1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(feature_name, feature_file, sub, save_regressed_y = False):  \n",
    "    results_save_dir = \"meg_sub\"+str(sub)+\"_predictions/\"\n",
    "    if not os.path.exists(results_save_dir):\n",
    "        os.mkdir(results_save_dir)\n",
    "    print(feature_name)\n",
    "    np.random.seed(9)\n",
    "    kf = KFold(n_splits=4)\n",
    "    features = np.load(feature_file, allow_pickle=True)\n",
    "#     features = np.load('bert-base-lw-5.npy', allow_pickle=True)\n",
    "#     features = np.load('glove_vecs_allstories.npy', allow_pickle=True)\n",
    "#     features = np.load('pos_tags_allstories.npy', allow_pickle=True)\n",
    "#     features = np.load('dep_tags_allstories.npy', allow_pickle=True)\n",
    "#     features = np.load('complexity_metrics.npy', allow_pickle=True)\n",
    "#     features_nc = np.load('nodecount_allstories.npy', allow_pickle=True)\n",
    "#     features_ss = np.load('syntactic_surprisal_allstories.npy', allow_pickle=True)\n",
    "#     features_wl = np.load('wordlen_allstories.npy', allow_pickle=True)\n",
    "#     features_wf = np.load('wordfreq_allstories.npy', allow_pickle=True)\n",
    "\n",
    "    save_dir = os.path.join(results_save_dir, feature_name)\n",
    "\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.mkdir(save_dir)\n",
    "    \n",
    "    data = np.load('sub0'+str(sub)+'-meg-data-ses0.npy', allow_pickle=True)\n",
    "    \n",
    "    for sub in np.arange(0,1):\n",
    "        \n",
    "        print(\"Subject \" + str(sub))\n",
    "        if os.path.exists(os.path.join(save_dir, str(sub) + \"_r2s.npy\")):\n",
    "            continue\n",
    "        \n",
    "        print(data.shape)\n",
    "        print(features.shape)\n",
    "\n",
    "        r2s = np.zeros(208*81)   \n",
    "        corr = np.zeros((208*81,2))\n",
    "\n",
    "        split_num = 0\n",
    "\n",
    "        all_preds = []\n",
    "        all_reals = []\n",
    "\n",
    "        for train, test in kf.split(np.arange(4)):\n",
    "            #for BERT\n",
    "            x_train = np.concatenate([np.array(features[train[0]][6]), np.array(features[train[1]][6]), np.array(features[train[2]][6])], axis=0)\n",
    "            x_test = np.array(features[test[0]][6])\n",
    "            #for POS, DEP, CM\n",
    "#             x_train = np.concatenate([np.array(features[train[0]]), np.array(features[train[1]]), np.array(features[train[2]])], axis=0)\n",
    "#             x_test = np.array(features[test[0]])\n",
    "            #for Nodecount, Wordlen\n",
    "#             x_train = np.concatenate([np.array(features[train[0]]).reshape(-1,1), np.array(features[train[1]]).reshape(-1,1), np.array(features[train[2]]).reshape(-1,1)], axis=0)\n",
    "#             x_test = np.array(features[test[0]]).reshape(-1,1)\n",
    "\n",
    "            y_train = np.concatenate([np.array(data[train[0]]).reshape(len(data[train[0]]),208*81), np.array(data[train[1]]).reshape(len(data[train[1]]),208*81), np.array(data[train[2]]).reshape(len(data[train[2]]),208*81)], axis=0)\n",
    "            y_test = np.array(data[test[0]]).reshape(len(data[test[0]]),208*81)\n",
    "            \n",
    "#             x_train = np.random.rand(y_train.shape[0],768)\n",
    "#             x_test = np.random.rand(y_test.shape[0],768)\n",
    "            #data = np.reshape(data,(data.shape[0],data.shape[1]*data.shape[2]))\n",
    "            \n",
    "#             x_train, x_test = features[train_index], features[test_index]\n",
    "#             y_train, y_test = data[train_index], data[test_index]\n",
    "            \n",
    "#             x_train = stats.zscore(x_train,axis=0)\n",
    "#             x_train = np.nan_to_num(x_train)\n",
    "\n",
    "#             x_test = stats.zscore(x_test,axis=0)\n",
    "#             x_test = np.nan_to_num(x_test)\n",
    "\n",
    "#             y_train = stats.zscore(y_train,axis=0)\n",
    "#             y_train = np.nan_to_num(y_train)\n",
    "\n",
    "#             y_test = stats.zscore(y_test,axis=0) \n",
    "#             y_test = np.nan_to_num(y_test)\n",
    "            \n",
    "            print(x_train.shape)\n",
    "            print(y_train.shape)\n",
    "            print(x_test.shape)\n",
    "            print(y_test.shape)\n",
    "\n",
    "            weights, lbda = cross_val_ridge(x_train,y_train)        \n",
    "            y_pred = np.dot(x_test,weights)\n",
    "\n",
    "            np.save(os.path.join(save_dir, \"{}_y_pred_{}\".format(str(sub), split_num)),np.nan_to_num(y_pred))\n",
    "            np.save(os.path.join(save_dir, \"{}_y_test_{}\".format(str(sub), split_num)),y_test)\n",
    "            #np.save(os.path.join(save_dir, \"{}_weights_{}\".format(str(sub), split_num)),weights)\n",
    "            np.save(os.path.join(save_dir, \"{}_lbda_{}\".format(str(sub), split_num)),lbda)\n",
    "            \n",
    "            if save_regressed_y:\n",
    "                y_pred_train = np.dot(x_train,weights)\n",
    "                np.save(os.path.join(save_dir, \"{}_y_regress_test_{}\".format(str(sub), split_num)),y_test - y_pred)\n",
    "                np.save(os.path.join(save_dir, \"{}_y_regress_train_{}\".format(str(sub), split_num)),y_train - y_pred_train)\n",
    "\n",
    "            split_num += 1\n",
    "\n",
    "            all_reals.append(y_test)\n",
    "            all_preds.append(y_pred)\n",
    "            #break\n",
    "\n",
    "        all_reals = np.vstack(all_reals)\n",
    "        all_preds = np.vstack(all_preds)\n",
    "\n",
    "        r2s = r2_score(all_reals,all_preds,multioutput=\"raw_values\")\n",
    "\n",
    "        for i in range(all_reals.shape[1]):\n",
    "            if np.nonzero(all_reals[:,i])[0].size > 0:\n",
    "                corr[i] = stats.pearsonr(all_reals[:,i],all_preds[:,i])\n",
    "            else:\n",
    "                r2s[i] = 0\n",
    "                corr[i][1] = 1\n",
    "\n",
    "        print(np.max(r2s))\n",
    "\n",
    "        np.save(os.path.join(save_dir, str(sub) + \"_r2s\"),np.nan_to_num(r2s))\n",
    "        np.save(os.path.join(save_dir, str(sub) + \"_corr\"),np.nan_to_num(corr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bertseq5rh_s0_predictions\n",
      "Subject 0\n",
      "(4,)\n",
      "(4,)\n",
      "(7893, 768)\n",
      "(7893, 16848)\n",
      "(668, 768)\n",
      "(668, 16848)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-a9df79e76600>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0meachfeature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mallfeatures\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'rh'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0meachfeature\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m             \u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'bertseq'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0meachfeature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'-'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'rh_s0_predictions'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0meachfeature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'bertseq'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0meachfeature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'-'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'_s0_predictions'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0meachfeature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-28-b7bc9e701b45>\u001b[0m in \u001b[0;36meval\u001b[1;34m(feature_name, feature_file, sub, save_regressed_y)\u001b[0m\n\u001b[0;32m     79\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m             \u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlbda\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_ridge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m             \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-19-5b1a76228c70>\u001b[0m in \u001b[0;36mcross_val_ridge\u001b[1;34m(train_features, train_data, n_splits, lambdas, method, do_plot)\u001b[0m\n\u001b[0;32m    120\u001b[0m         cost = ridge_1(train_features[trn],train_data[trn],\n\u001b[0;32m    121\u001b[0m                                \u001b[0mtrain_features\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 122\u001b[1;33m                                lambdas=lambdas)\n\u001b[0m\u001b[0;32m    123\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdo_plot\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-19-5b1a76228c70>\u001b[0m in \u001b[0;36mridge_by_lambda\u001b[1;34m(X, Y, Xval, Yval, lambdas)\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[0merror\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlambdas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlmbda\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlambdas\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m         \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mridge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlmbda\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m         \u001b[0merror\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mR2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mYval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-19-5b1a76228c70>\u001b[0m in \u001b[0;36mridge\u001b[1;34m(X, Y, lmbda)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mridge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlmbda\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mlmbda\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meye\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mridge_by_lambda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mYval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlambdas\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "allfeatures = ['bert-base-lw-5.npy','bert-base-lw-rh-5.npy','bert-base-lw-rh-20.npy','bert-base-lw-4.npy']\n",
    "for sub in np.arange(2,9):\n",
    "    for eachfeature in allfeatures:\n",
    "        if 'rh' in eachfeature:\n",
    "            eval('bertseq'+eachfeature.split('-')[-1].split('.')[0]+'rh_s0_predictions',eachfeature,sub)\n",
    "        else:\n",
    "            eval('bertseq'+eachfeature.split('-')[-1].split('.')[0]+'_s0_predictions',eachfeature,sub)\n",
    "        break\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
