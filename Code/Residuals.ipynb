{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy import stats\n",
    "from sklearn.decomposition import PCA\n",
    "from IPython.core.debugger import set_trace\n",
    "import pickle\n",
    "import os\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to estimate cost for each lambda, by voxel:\n",
    "from __future__ import division                                              \n",
    "\n",
    "from numpy.linalg import inv, svd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import Ridge, RidgeCV\n",
    "import time \n",
    "from scipy.stats import zscore\n",
    "\n",
    "\n",
    "def corr(X,Y):\n",
    "    return np.mean(zscore(X)*zscore(Y),0)\n",
    "\n",
    "def R2(Pred,Real):\n",
    "    SSres = np.mean((Real-Pred)**2,0)\n",
    "    SStot = np.var(Real,0)\n",
    "    return np.nan_to_num(1-SSres/SStot)\n",
    "\n",
    "def R2r(Pred,Real):\n",
    "    R2rs = R2(Pred,Real)\n",
    "    ind_neg = R2rs<0\n",
    "    R2rs = np.abs(R2rs)\n",
    "    R2rs = np.sqrt(R2rs)\n",
    "    R2rs[ind_neg] *= - 1\n",
    "    return R2rs\n",
    "\n",
    "def ridge(X,Y,lmbda):\n",
    "    return np.dot(inv(X.T.dot(X)+lmbda*np.eye(X.shape[1])),X.T.dot(Y))\n",
    "\n",
    "def ridge_by_lambda(X, Y, Xval, Yval, lambdas=np.array([0.1,1,10,100,1000])):\n",
    "    error = np.zeros((lambdas.shape[0],Y.shape[1]))\n",
    "    for idx,lmbda in enumerate(lambdas):\n",
    "        weights = ridge(X,Y,lmbda)\n",
    "        error[idx] = 1 - R2(np.dot(Xval,weights),Yval)\n",
    "    return error\n",
    "\n",
    "def ridge_sk(X,Y,lmbda):\n",
    "    rd = Ridge(alpha = lmbda)\n",
    "    rd.fit(X,Y)\n",
    "    return rd.coef_.T\n",
    "\n",
    "def ridgeCV_sk(X,Y,lmbdas):\n",
    "    rd = RidgeCV(alphas = lmbdas,solver = 'svd')\n",
    "    rd.fit(X,Y)\n",
    "    return rd.coef_.T\n",
    "\n",
    "def ridge_by_lambda_sk(X, Y, Xval, Yval, lambdas=np.array([0.1,1,10,100,1000])):\n",
    "    error = np.zeros((lambdas.shape[0],Y.shape[1]))\n",
    "    for idx,lmbda in enumerate(lambdas):\n",
    "        weights = ridge_sk(X,Y,lmbda)\n",
    "        error[idx] = 1 -  R2(np.dot(Xval,weights),Yval)\n",
    "    return error\n",
    "\n",
    "def ridge_svd(X,Y,lmbda):\n",
    "    U, s, Vt = svd(X, full_matrices=False)\n",
    "    d = s / (s** 2 + lmbda)\n",
    "    return np.dot(Vt,np.diag(d).dot(U.T.dot(Y)))\n",
    "\n",
    "def ridge_by_lambda_svd(X, Y, Xval, Yval, lambdas=np.array([0.1,1,10,100,1000])):\n",
    "    error = np.zeros((lambdas.shape[0],Y.shape[1]))\n",
    "    U, s, Vt = svd(X, full_matrices=False)\n",
    "    for idx,lmbda in enumerate(lambdas):\n",
    "        d = s / (s** 2 + lmbda)\n",
    "        weights = np.dot(Vt,np.diag(d).dot(U.T.dot(Y)))\n",
    "        error[idx] = 1 - R2(np.dot(Xval,weights),Yval)\n",
    "    return error\n",
    "\n",
    "\n",
    "def kernel_ridge(X,Y,lmbda):\n",
    "    return np.dot(X.T.dot(inv(X.dot(X.T)+lmbda*np.eye(X.shape[0]))),Y)\n",
    "\n",
    "def kernel_ridge_by_lambda(X, Y, Xval, Yval, lambdas=np.array([0.1,1,10,100,1000])):\n",
    "    error = np.zeros((lambdas.shape[0],Y.shape[1]))\n",
    "    for idx,lmbda in enumerate(lambdas):\n",
    "        weights = kernel_ridge(X,Y,lmbda)\n",
    "        error[idx] = 1 - R2(np.dot(Xval,weights),Yval)\n",
    "    return error\n",
    "\n",
    "\n",
    "def kernel_ridge_svd(X,Y,lmbda):\n",
    "    U, s, Vt = svd(X.T, full_matrices=False)\n",
    "    d = s / (s** 2 + lmbda)\n",
    "    return np.dot(np.dot(U,np.diag(d).dot(Vt)),Y)\n",
    "\n",
    "def kernel_ridge_by_lambda_svd(X, Y, Xval, Yval, lambdas=np.array([0.1,1,10,100,1000])):\n",
    "    error = np.zeros((lambdas.shape[0],Y.shape[1]))\n",
    "    U, s, Vt = svd(X.T, full_matrices=False)\n",
    "    for idx,lmbda in enumerate(lambdas):\n",
    "        d = s / (s** 2 + lmbda)\n",
    "        weights = np.dot(np.dot(U,np.diag(d).dot(Vt)),Y)\n",
    "        error[idx] = 1 - R2(np.dot(Xval,weights),Yval)\n",
    "    return error\n",
    "\n",
    "\n",
    "def cross_val_ridge(train_features,train_data, n_splits = 10, \n",
    "                    lambdas = np.array([10**i for i in range(-6,10)]),\n",
    "                    method = 'plain',\n",
    "                    do_plot = False):\n",
    "    \n",
    "    ridge_1 = dict(plain = ridge_by_lambda,\n",
    "                   svd = ridge_by_lambda_svd,\n",
    "                   kernel_ridge = kernel_ridge_by_lambda,\n",
    "                   kernel_ridge_svd = kernel_ridge_by_lambda_svd,\n",
    "                   ridge_sk = ridge_by_lambda_sk)[method]\n",
    "    ridge_2 = dict(plain = ridge,\n",
    "                   svd = ridge_svd,\n",
    "                   kernel_ridge = kernel_ridge,\n",
    "                   kernel_ridge_svd = kernel_ridge_svd,\n",
    "                   ridge_sk = ridge_sk)[method]\n",
    "    \n",
    "    n_voxels = train_data.shape[1]\n",
    "    nL = lambdas.shape[0]\n",
    "    r_cv = np.zeros((nL, train_data.shape[1]))\n",
    "\n",
    "    kf = KFold(n_splits=n_splits)\n",
    "    start_t = time.time()\n",
    "    for icv, (trn, val) in enumerate(kf.split(train_data)):\n",
    "#         print('ntrain = {}'.format(train_features[trn].shape[0]))\n",
    "        cost = ridge_1(train_features[trn],train_data[trn],\n",
    "                               train_features[val],train_data[val], \n",
    "                               lambdas=lambdas)\n",
    "        if do_plot:\n",
    "            import matplotlib.pyplot as plt\n",
    "            plt.figure()\n",
    "            plt.imshow(cost,aspect = 'auto')\n",
    "        r_cv += cost\n",
    "#         if icv%3 ==0:\n",
    "#             print(icv)\n",
    "#         print('average iteration length {}'.format((time.time()-start_t)/(icv+1)))\n",
    "    if do_plot:\n",
    "        plt.figure()\n",
    "        plt.imshow(r_cv,aspect='auto',cmap = 'RdBu_r');\n",
    "\n",
    "    argmin_lambda = np.argmin(r_cv,axis = 0)\n",
    "    weights = np.zeros((train_features.shape[1],train_data.shape[1]))\n",
    "    for idx_lambda in range(lambdas.shape[0]): # this is much faster than iterating over voxels!\n",
    "        idx_vox = argmin_lambda == idx_lambda\n",
    "        weights[:,idx_vox] = ridge_2(train_features, train_data[:,idx_vox],lambdas[idx_lambda])\n",
    "    if do_plot:\n",
    "        plt.figure()\n",
    "        plt.imshow(weights,aspect='auto',cmap = 'RdBu_r',vmin = -0.5,vmax = 0.5);\n",
    "\n",
    "    return weights, np.array([lambdas[i] for i in argmin_lambda])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def GCV_ridge(train_features,train_data,lambdas = np.array([10**i for i in range(-6,10)])):\n",
    "    \n",
    "    n_lambdas = lambdas.shape[0]\n",
    "    n_voxels = train_data.shape[1]\n",
    "    n_time = train_data.shape[0]\n",
    "    n_p = train_features.shape[1]\n",
    "\n",
    "    CVerr = np.zeros((n_lambdas, n_voxels))\n",
    "\n",
    "    # % If we do an eigendecomp first we can quickly compute the inverse for many different values\n",
    "    # % of lambda. SVD uses X = UDV' form.\n",
    "    # % First compute K0 = (X'X + lambda*I) where lambda = 0.\n",
    "    #K0 = np.dot(train_features,train_features.T)\n",
    "    print('Running svd',)\n",
    "    start_time = time.time()\n",
    "    [U,D,Vt] = svd(train_features,full_matrices=False)\n",
    "    V = Vt.T\n",
    "    print(U.shape,D.shape,Vt.shape)\n",
    "    print('svd time: {}'.format(time.time() - start_time))\n",
    "\n",
    "    for i,regularizationParam in enumerate(lambdas):\n",
    "        regularizationParam = lambdas[i]\n",
    "        print('CVLoop: Testing regularization param: {}'.format(regularizationParam))\n",
    "\n",
    "        #Now we can obtain Kinv for any lambda doing Kinv = V * (D + lambda*I)^-1 U'\n",
    "        dlambda = D**2 + np.eye(n_p)*regularizationParam\n",
    "        dlambdaInv = np.diag(D / np.diag(dlambda))\n",
    "        KlambdaInv = V.dot(dlambdaInv).dot(U.T)\n",
    "        \n",
    "        # Compute S matrix of Hastie Trick  H = X(XT X + lambdaI)-1XT\n",
    "        S = np.dot(U, np.diag(D * np.diag(dlambdaInv))).dot(U.T)\n",
    "        denum = 1-np.trace(S)/n_time\n",
    "        \n",
    "        # Solve for weight matrix so we can compute residual\n",
    "        weightMatrix = KlambdaInv.dot(train_data);\n",
    "\n",
    "\n",
    "#         Snorm = np.tile(1 - np.diag(S) , (n_voxels, 1)).T\n",
    "        YdiffMat = (train_data - (train_features.dot(weightMatrix)));\n",
    "        YdiffMat = YdiffMat / denum;\n",
    "        CVerr[i,:] = (1/n_time)*np.sum(YdiffMat * YdiffMat,0);\n",
    "\n",
    "\n",
    "    # try using min of avg err\n",
    "    minerrIndex = np.argmin(CVerr,axis = 0);\n",
    "    r=np.zeros((n_voxels));\n",
    "\n",
    "    for nPar,regularizationParam in enumerate(lambdas):\n",
    "        ind = np.where(minerrIndex==nPar)[0];\n",
    "        if len(ind)>0:\n",
    "            r[ind] = regularizationParam;\n",
    "            print('{}% of outputs with regularization param: {}'.format(int(len(ind)/n_voxels*100),\n",
    "                                                                        regularizationParam))\n",
    "            # got good param, now obtain weights\n",
    "            dlambda = D**2 + np.eye(n_p)*regularizationParam\n",
    "            dlambdaInv = np.diag(D / np.diag(dlambda))\n",
    "            KlambdaInv = V.dot(dlambdaInv).dot(U.T)\n",
    "\n",
    "            weightMatrix[:,ind] = KlambdaInv.dot(train_data[:,ind]);\n",
    "\n",
    "\n",
    "    return weightMatrix, r\n",
    "\n",
    "def sub_to_subjectnum(sub):\n",
    "    for i in range(len(all_subjects)):\n",
    "        if all_subjects[i] == sub:\n",
    "            return i+1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(feature_name, context5, context1, save_regressed_y = False):  \n",
    "    print(feature_name)\n",
    "    save_dir = '.'\n",
    "    np.random.seed(9)\n",
    "    kf = KFold(n_splits=4)\n",
    "    \n",
    "    data = np.load('bert-base-lw-4.npy', allow_pickle=True)\n",
    "    \n",
    "    for sub in np.arange(0,1):\n",
    "        \n",
    "        print(\"Subject \" + str(sub))\n",
    "        if os.path.exists(os.path.join(save_dir, str(sub) + \"_r2s.npy\")):\n",
    "            continue\n",
    "        \n",
    "        print(data.shape)\n",
    "\n",
    "        r2s = np.zeros(768)   \n",
    "        corr = np.zeros(768)\n",
    "\n",
    "        split_num = 0\n",
    "\n",
    "        all_preds = []\n",
    "        all_reals = []\n",
    "\n",
    "        for train, test in kf.split(np.arange(4)):\n",
    "            #for BERT\n",
    "            x_train = np.array(context5[test[0]][6])-np.array(context1[test[0]][6])\n",
    "            x_test = np.array(context5[test[0]][6])-np.array(context1[test[0]][6])\n",
    "            \n",
    "            y_train = np.array(data[test[0]][6])\n",
    "            y_test = np.array(data[test[0]][6])\n",
    "            \n",
    "            print(x_train.shape)\n",
    "            print(y_train.shape)\n",
    "            print(x_test.shape)\n",
    "            print(y_test.shape)\n",
    "\n",
    "            weights, lbda = cross_val_ridge(x_train,y_train)        \n",
    "            y_pred = np.dot(x_test,weights)\n",
    "\n",
    "            np.save(os.path.join(save_dir, \"{}_y_pred_{}\".format(str(sub), split_num)),np.nan_to_num(y_pred))\n",
    "            np.save(os.path.join(save_dir, \"{}_y_test_{}\".format(str(sub), split_num)),y_test)\n",
    "            #np.save(os.path.join(save_dir, \"{}_weights_{}\".format(str(sub), split_num)),weights)\n",
    "            np.save(os.path.join(save_dir, \"{}_lbda_{}\".format(str(sub), split_num)),lbda)\n",
    "            \n",
    "            if save_regressed_y:\n",
    "                y_pred_train = np.dot(x_train,weights)\n",
    "                np.save(os.path.join(save_dir, \"{}_y_regress_test_{}\".format(str(sub), split_num)),y_test - y_pred)\n",
    "                np.save(os.path.join(save_dir, \"{}_y_regress_train_{}\".format(str(sub), split_num)),y_train - y_pred_train)\n",
    "\n",
    "            split_num += 1\n",
    "\n",
    "            all_reals.append(y_test)\n",
    "            all_preds.append(y_pred)\n",
    "            #break\n",
    "\n",
    "        all_reals = np.vstack(all_reals)\n",
    "        all_preds = np.vstack(all_preds)\n",
    "\n",
    "        r2s = r2_score(all_reals,all_preds,multioutput=\"raw_values\")\n",
    "\n",
    "        for i in range(all_reals.shape[1]):\n",
    "            if np.nonzero(all_reals[:,i])[0].size > 0:\n",
    "                corr[i] = stats.pearsonr(all_reals[:,i],all_preds[:,i])\n",
    "            else:\n",
    "                r2s[i] = 0\n",
    "                corr[i][1] = 1\n",
    "\n",
    "        print(np.max(r2s))\n",
    "\n",
    "        np.save(os.path.join(save_dir, str(sub) + \"_r2s\"),np.nan_to_num(r2s))\n",
    "        np.save(os.path.join(save_dir, str(sub) + \"_corr\"),np.nan_to_num(corr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "context5 = np.load(\"bert-base-lw-5.npy\",allow_pickle=True)\n",
    "context1 = np.load(\"bert-base-lw-1.npy\",allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "residuals\n",
      "Subject 0\n",
      "(4,)\n",
      "(668, 768)\n",
      "(668, 768)\n",
      "(668, 768)\n",
      "(668, 768)\n",
      "(1503, 768)\n",
      "(1503, 768)\n",
      "(1503, 768)\n",
      "(1503, 768)\n",
      "(2637, 768)\n",
      "(2637, 768)\n",
      "(2637, 768)\n",
      "(2637, 768)\n",
      "(3753, 768)\n",
      "(3753, 768)\n",
      "(3753, 768)\n",
      "(3753, 768)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'tuple'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-bae533bc0aeb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"residuals\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcontext5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-12-352df53ae847>\u001b[0m in \u001b[0;36meval\u001b[1;34m(feature_name, context5, context1, save_regressed_y)\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_reals\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_reals\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m                 \u001b[0mcorr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpearsonr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_reals\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mall_preds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m                 \u001b[0mr2s\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "eval(\"residuals\",context5, context1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "residual_context = []\n",
    "for i in np.arange(4):\n",
    "    aa = np.load(\"0_y_pred_\"+str(i)+\".npy\")\n",
    "    residual_context.append(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\test\\anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py:528: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.asanyarray(arr)\n"
     ]
    }
   ],
   "source": [
    "np.save(\"bert_residual_context4\",residual_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(668, 768)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "residual_context[3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
